{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from input...\n"
     ]
    }
   ],
   "source": [
    "# extract the input as a stream of characters\n",
    "print(\"Extracting text from input...\")\n",
    "fin = open(INPUT_FILE, 'rb')\n",
    "lines = []\n",
    "for line in fin:\n",
    "    line = line.strip().lower()\n",
    "    line = line.decode(\"ascii\", \"ignore\")\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "fin.close()\n",
    "text = \" \".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating lookup tables\n",
    "# Here chars is the number of features in our character \"vocabulary\"\n",
    "chars = set([c for c in text])\n",
    "nb_chars = len(chars)\n",
    "char2index = dict((c, i) for i, c in enumerate(chars))\n",
    "index2char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating input and label text...\n"
     ]
    }
   ],
   "source": [
    "# create inputs and labels from the text. We do this by stepping\n",
    "# through the text ${step} character at a time, and extracting a \n",
    "# sequence of size ${seqlen} and the next output char. For example,\n",
    "# assuming an input text \"The sky was falling\", we would get the \n",
    "# following sequence of input_chars and label_chars (first 5 only)\n",
    "#   The sky wa -> s\n",
    "#   he sky was ->  \n",
    "#   e sky was  -> f\n",
    "#    sky was f -> a\n",
    "#   sky was fa -> l\n",
    "print(\"Creating input and label text...\")\n",
    "SEQLEN = 10\n",
    "STEP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_chars = []\n",
    "label_chars = []\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i:i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing input and label text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_7236\\2292689834.py:10: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_7236\\2292689834.py:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "# vectorize the input and label chars\n",
    "# Each row of the input is represented by seqlen characters, each \n",
    "# represented as a 1-hot encoding of size len(char). There are \n",
    "# len(input_chars) such rows, so shape(X) is (len(input_chars),\n",
    "# seqlen, nb_chars).\n",
    "# Each row of output is a single character, also represented as a\n",
    "# dense encoding of size len(char). Hence shape(y) is (len(input_chars),\n",
    "# nb_chars).\n",
    "print(\"Vectorizing input and label text...\")\n",
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to compute the most likely predicted output char\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "NUM_ITERATIONS = 25\n",
    "NUM_EPOCHS_PER_ITERATION = 1\n",
    "NUM_PREDS_PER_EPOCH = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(HIDDEN_SIZE, return_sequences=False,\n",
    "                    input_shape=(SEQLEN, nb_chars),\n",
    "                    unroll=True))\n",
    "model.add(Dense(nb_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteration #: 0\n",
      "1241/1241 [==============================] - 11s 7ms/step - loss: 2.3356\n",
      "Generating from seed: little shr\n",
      "little shr has in and the southe southe southe southe southe southe southe southe southe southe southe southe \n",
      "==================================================\n",
      "Iteration #: 1\n",
      "1241/1241 [==============================] - 9s 7ms/step - loss: 2.0469\n",
      "Generating from seed:  looked do\n",
      " looked do the was in and the was in and the was in and the was in and the was in and the was in and the was i\n",
      "==================================================\n",
      "Iteration #: 2\n",
      "1241/1241 [==============================] - 9s 7ms/step - loss: 1.9443\n",
      "Generating from seed: i dont tak\n",
      "i dont take the could the grypurke whith the was the grypurke whith the was the grypurke whith the was the gry\n",
      "==================================================\n",
      "Iteration #: 3\n",
      "1241/1241 [==============================] - 9s 7ms/step - loss: 1.8630\n",
      "Generating from seed: s: youd be\n",
      "s: youd be the goter alice and the goter alice and the goter alice and the goter alice and the goter alice and\n",
      "==================================================\n",
      "Iteration #: 4\n",
      "1241/1241 [==============================] - 9s 8ms/step - loss: 1.7951\n",
      "Generating from seed: wling so m\n",
      "wling so ment on the soof the mouse the mouse the mouse the mouse the mouse the mouse the mouse the mouse the \n",
      "==================================================\n",
      "Iteration #: 5\n",
      "1241/1241 [==============================] - 8s 7ms/step - loss: 1.7392\n",
      "Generating from seed: ing, and h\n",
      "ing, and har the the she her her here the soom the mare said to be to the the could and the said to be to the \n",
      "==================================================\n",
      "Iteration #: 6\n",
      "1241/1241 [==============================] - 8s 7ms/step - loss: 1.6937\n",
      "Generating from seed: ortant to \n",
      "ortant to her here the got of the orem the mound the pooked the rabe the gryphon a cones to the got of the ore\n",
      "==================================================\n",
      "Iteration #: 7\n",
      "1241/1241 [==============================] - 10s 8ms/step - loss: 1.6542\n",
      "Generating from seed: and the tw\n",
      "and the twork of the was the grople said the dormouse she was the grople said the dormouse she was the grople \n",
      "==================================================\n",
      "Iteration #: 8\n",
      "1241/1241 [==============================] - 10s 8ms/step - loss: 1.6218\n",
      "Generating from seed: e in silen\n",
      "e in silent with the eare to the ear she was she was she was she was she was she was she was she was she was s\n",
      "==================================================\n",
      "Iteration #: 9\n",
      "1241/1241 [==============================] - 10s 8ms/step - loss: 1.5928\n",
      "Generating from seed: t out loud\n",
      "t out loud and the courte to the began and the courte to the began and the courte to the began and the courte \n",
      "==================================================\n",
      "Iteration #: 10\n",
      "1241/1241 [==============================] - 9s 7ms/step - loss: 1.5678\n",
      "Generating from seed: ed it arru\n",
      "ed it arrup and the doom the cat on the the reaming the mouse on the while the while the while the while the w\n",
      "==================================================\n",
      "Iteration #: 11\n",
      "1241/1241 [==============================] - 9s 7ms/step - loss: 1.5460\n",
      "Generating from seed: , how late\n",
      ", how late the door and hear the door and hear the door and hear the door and hear the door and hear the door \n",
      "==================================================\n",
      "Iteration #: 12\n",
      "1241/1241 [==============================] - 9s 7ms/step - loss: 1.5269\n",
      "Generating from seed:  different\n",
      " different of the door of the door of the door of the door of the door of the door of the door of the door of \n",
      "==================================================\n",
      "Iteration #: 13\n",
      "1241/1241 [==============================] - 9s 7ms/step - loss: 1.5100\n",
      "Generating from seed: ll his eye\n",
      "ll his eyes and the ears of the looked at the took alice was not the earss of the took alice was not the earss\n",
      "==================================================\n",
      "Iteration #: 14\n",
      "1241/1241 [==============================] - 9s 8ms/step - loss: 1.4928\n",
      "Generating from seed: momile tha\n",
      "momile that she down to say to so the things of the things of the things of the things of the things of the th\n",
      "==================================================\n",
      "Iteration #: 15\n",
      "1241/1241 [==============================] - 9s 7ms/step - loss: 1.4790\n",
      "Generating from seed: mation abo\n",
      "mation about the mouse so the found at and the thing it and went on and were and the formation a grow what i g\n",
      "==================================================\n",
      "Iteration #: 16\n",
      "1241/1241 [==============================] - 11s 9ms/step - loss: 1.4660\n",
      "Generating from seed: e little b\n",
      "e little began the court and the hatter was the for a more to her from of the some the court and the hatter wa\n",
      "==================================================\n",
      "Iteration #: 17\n",
      "1241/1241 [==============================] - 11s 8ms/step - loss: 1.4536\n",
      "Generating from seed:  the next \n",
      " the next a little began and all the realled to get in the little she was not the little she was not the littl\n",
      "==================================================\n",
      "Iteration #: 18\n",
      "1241/1241 [==============================] - 10s 8ms/step - loss: 1.4431\n",
      "Generating from seed: illar. her\n",
      "illar. her she was a little thing in a mouse in a mouse in a mouse in a mouse in a mouse in a mouse in a mouse\n",
      "==================================================\n",
      "Iteration #: 19\n",
      "1241/1241 [==============================] - 10s 8ms/step - loss: 1.4328\n",
      "Generating from seed: utor under\n",
      "utor under the three cat of the some the should the same the she should the same the she should the same the s\n",
      "==================================================\n",
      "Iteration #: 20\n",
      "1241/1241 [==============================] - 9s 8ms/step - loss: 1.4235\n",
      "Generating from seed: ing but on\n",
      "ing but on the same the said the doceds of course the way a little with the mock turtle with the mock turtle w\n",
      "==================================================\n",
      "Iteration #: 21\n",
      "1241/1241 [==============================] - 9s 8ms/step - loss: 1.4148\n",
      "Generating from seed: les. it wa\n",
      "les. it was so much so much at the project gutenberg-tm electronic works in the project gutenberg-tm electroni\n",
      "==================================================\n",
      "Iteration #: 22\n",
      "1241/1241 [==============================] - 9s 7ms/step - loss: 1.4076\n",
      "Generating from seed: hat a mome\n",
      "hat a moment the execution of the change the white rabbit was and remeable to see what the mouse of the projec\n",
      "==================================================\n",
      "Iteration #: 23\n",
      "1241/1241 [==============================] - 9s 7ms/step - loss: 1.4005\n",
      "Generating from seed: ut she was\n",
      "ut she was she was she was she was she was she was she was she was she was she was she was she was she was she\n",
      "==================================================\n",
      "Iteration #: 24\n",
      "1241/1241 [==============================] - 13s 10ms/step - loss: 1.3934\n",
      "Generating from seed: y it was! \n",
      "y it was! said the king. the king said to the gryphon about the gryphon about the gryphon about the gryphon ab\n"
     ]
    }
   ],
   "source": [
    "# We train the model in batches and test output generated at each step\n",
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteration #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)\n",
    "    \n",
    "    # testing model\n",
    "    # randomly choose a row from input_chars, then use it to \n",
    "    # generate text from model for next 100 chars\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "    print(\"Generating from seed: %s\" % (test_chars))\n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(NUM_PREDS_PER_EPOCH):\n",
    "        Xtest = np.zeros((1, SEQLEN, nb_chars))\n",
    "        for i, ch in enumerate(test_chars):\n",
    "            Xtest[0, i, char2index[ch]] = 1\n",
    "        pred = model.predict(Xtest, verbose=0)[0]\n",
    "        ypred = index2char[np.argmax(pred)]\n",
    "        print(ypred, end=\"\")\n",
    "        # move forward with test_chars + ypred\n",
    "        test_chars = test_chars[1:] + ypred\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f5583cf1d9466b5c27e75c89cc6b383bed5736d6b16c51c8074d8690011a952"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
