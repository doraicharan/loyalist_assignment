{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c06cad86-8bb6-4021-b33f-8e3d419220cb",
   "metadata": {},
   "source": [
    "# Application Exercise 2 - AISC2009 - Natural Language Processing 01\n",
    "## Group-D\n",
    "1. Dorai Charan Simha Muthineni - 500185125<br>\n",
    "2. Krishna Vamsi Vanga - 500187921<br>\n",
    "3. Naveen Kumar Pathi - 500187816<br>\n",
    "4. Sai Chand Devarapalli - 500192020<br>\n",
    "5. Venkatesh Policherla - 500194692<br>\n",
    "6. Christy George Thomas - 500187205"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0014139a-a0e7-4747-be11-d02596106ceb",
   "metadata": {},
   "source": [
    "## 1. Read your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086f9787-a05f-4183-a0df-1b6e1bcb5224",
   "metadata": {},
   "source": [
    "### 1a.\n",
    "Read in your text data (files provided at Moodle) and save it into a data frame called “dataset”. \n",
    "Tip: You may use read_csv in Pandas to read in the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e39fdea-ea48-43fd-a517-65272cb395c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a57b79e-a369-454f-87bc-b65d3d987502",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Youtube05-Shakira.csv')  # Reading the data using pandas.read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0d1f20-b06a-4247-a26a-ff9f5f021507",
   "metadata": {},
   "source": [
    "### 1b.\n",
    "Figure out how many rows and columns are in “dataset”. \n",
    "Note: Study the dataset. Then, you must choose the column(s) needed for pre-processing. \n",
    "Note: Since, you are not fitting ML model in this exercise, you may only proceed with a column containing text messages. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00d5e267-5aec-4072-a428-c54f362148d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 370 entries, 0 to 369\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   COMMENT_ID  370 non-null    object\n",
      " 1   AUTHOR      370 non-null    object\n",
      " 2   DATE        370 non-null    object\n",
      " 3   CONTENT     370 non-null    object\n",
      " 4   CLASS       370 non-null    int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 14.6+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()  # Used to find nullvalues, dtype of columns and shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee82961e-1b70-497e-80b4-77db449353a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(370, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape  # Used to find the shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82b9ba37-545a-4b18-9c13-66baa10de44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z13lgffb5w3ddx1ul22qy1wxspy5cpkz504</td>\n",
       "      <td>dharma pal</td>\n",
       "      <td>2015-05-29T02:30:18.971000</td>\n",
       "      <td>Nice song﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>z123dbgb0mqjfxbtz22ucjc5jvzcv3ykj</td>\n",
       "      <td>Tiza Arellano</td>\n",
       "      <td>2015-05-29T00:14:48.748000</td>\n",
       "      <td>I love song ﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>z12quxxp2vutflkxv04cihggzt2azl34pms0k</td>\n",
       "      <td>Prìñçeśś Âliś Łøvê Dømíñø Mâđiś™ ﻿</td>\n",
       "      <td>2015-05-28T21:00:08.607000</td>\n",
       "      <td>I love song ﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              COMMENT_ID                              AUTHOR  \\\n",
       "0    z13lgffb5w3ddx1ul22qy1wxspy5cpkz504                          dharma pal   \n",
       "1      z123dbgb0mqjfxbtz22ucjc5jvzcv3ykj                       Tiza Arellano   \n",
       "2  z12quxxp2vutflkxv04cihggzt2azl34pms0k  Prìñçeśś Âliś Łøvê Dømíñø Mâđiś™ ﻿   \n",
       "\n",
       "                         DATE        CONTENT  CLASS  \n",
       "0  2015-05-29T02:30:18.971000     Nice song﻿      0  \n",
       "1  2015-05-29T00:14:48.748000  I love song ﻿      0  \n",
       "2  2015-05-28T21:00:08.607000  I love song ﻿      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(3)  # Used to print first 3 rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a689d42-8d59-4d77-af09-dfb83d076935",
   "metadata": {},
   "source": [
    "### Using only one column 'CONTENT' for the dataset\n",
    "Here we use only one column since we are only doing text-preprocessing in this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daea1327-e329-474d-bbf6-c42e493b23cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.CONTENT  # Updating the dataset to only one column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdfc77c-5dab-495b-aef4-0843a2a76c02",
   "metadata": {},
   "source": [
    "### 1c.\n",
    "Check for any missing data in your data frame and display the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffd2037a-f053-4118-ae45-997a0423d503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()  # Gives total number of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1343ca3d-5d59-4eba-812a-5509c07fc519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           Nice song﻿\n",
       "1                                        I love song ﻿\n",
       "2                                        I love song ﻿\n",
       "3    860,000,000 lets make it first female to reach...\n",
       "4                        shakira is best for worldcup﻿\n",
       "Name: CONTENT, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()  # Prints first five rows of the dataframe by default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12c2c7b-fee3-4df5-8ae2-6fce42d14459",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dacac6-f79a-4ece-aab7-ba58c55f3e40",
   "metadata": {},
   "source": [
    "## 2. Remove Punctuatuions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef450bbc-4740-4537-ba5c-418379fbe5f3",
   "metadata": {},
   "source": [
    "### 2a.\n",
    "Write a Python function to remove punctuations from text and save the transformed text in a new column in your data frame called “punct_text”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "289ae35e-bd29-4c6b-9ca0-14ebe74dbf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below we write a user defined function to remove punctuations from a sentence using regex\n",
    "def remove_punctuatuion(comment):  # takes a string as a input\n",
    "    return re.sub(r'[^\\w\\s]', '', comment)  # outputs a string with punctuation removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f5dee0c-8d5e-42be-ab0c-b87c16ddab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_punct = pd.Series(dataset.map(lambda x:remove_punctuatuion(x)), name=\"punct_text\") \n",
    "# Here we use map function to trnasform each element of the column using our user defined function\n",
    "# And save the new data into a series called no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2250419-9a33-43eb-932e-3a9381b94dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                            Nice song\n",
       "1                                         I love song \n",
       "2                                         I love song \n",
       "3    860000000 lets make it first female to reach o...\n",
       "4                         shakira is best for worldcup\n",
       "Name: punct_text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_punct.head()  # Prints first five rows of the dataframe by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b764d6f0-a121-4178-946d-223993607388",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([dataset, no_punct], axis=1)  # Joins two Series to form a dataframe here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c4e99f-663c-4158-9ce6-fe65b7b79b47",
   "metadata": {},
   "source": [
    "### 2b.\n",
    "Then, printout the first few rows of your data frame.\n",
    "Note: Make sure the text is in the format of sentences NOT separated characters after this step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e0d085c-d2d5-463a-9be8-cea4325717bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>punct_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nice song﻿</td>\n",
       "      <td>Nice song</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love song ﻿</td>\n",
       "      <td>I love song</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love song ﻿</td>\n",
       "      <td>I love song</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>860,000,000 lets make it first female to reach...</td>\n",
       "      <td>860000000 lets make it first female to reach o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shakira is best for worldcup﻿</td>\n",
       "      <td>shakira is best for worldcup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The best world cup song ever!!!!﻿</td>\n",
       "      <td>The best world cup song ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I love﻿</td>\n",
       "      <td>I love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SEE SOME MORE SONG OPEN GOOGLE AND TYPE Shakir...</td>\n",
       "      <td>SEE SOME MORE SONG OPEN GOOGLE AND TYPE Shakir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Awesome ﻿</td>\n",
       "      <td>Awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I like shakira..﻿</td>\n",
       "      <td>I like shakira</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             CONTENT  \\\n",
       "0                                         Nice song﻿   \n",
       "1                                      I love song ﻿   \n",
       "2                                      I love song ﻿   \n",
       "3  860,000,000 lets make it first female to reach...   \n",
       "4                      shakira is best for worldcup﻿   \n",
       "5                  The best world cup song ever!!!!﻿   \n",
       "6                                            I love﻿   \n",
       "7  SEE SOME MORE SONG OPEN GOOGLE AND TYPE Shakir...   \n",
       "8                                          Awesome ﻿   \n",
       "9                                  I like shakira..﻿   \n",
       "\n",
       "                                          punct_text  \n",
       "0                                          Nice song  \n",
       "1                                       I love song   \n",
       "2                                       I love song   \n",
       "3  860000000 lets make it first female to reach o...  \n",
       "4                       shakira is best for worldcup  \n",
       "5                       The best world cup song ever  \n",
       "6                                             I love  \n",
       "7  SEE SOME MORE SONG OPEN GOOGLE AND TYPE Shakir...  \n",
       "8                                           Awesome   \n",
       "9                                     I like shakira  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)  # Prints first ten rows of the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9829aae5-bc8f-49b0-a37d-37bb27ea96ab",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662cb51-c777-4679-8abe-f2ce55ace97c",
   "metadata": {},
   "source": [
    "## 3. Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0df7f8-52ea-44f4-a012-c99360579dc3",
   "metadata": {},
   "source": [
    "### 3a., 3c.\n",
    "a.\tWrite a function to tokenize the text and save the tokenized text in a new column in your data frame called “token_text”. <br>\n",
    "c.\tYou may use lower() function such that all the text converts to lower case and explain why this is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "091c5501-719a-4df3-a27c-7189987ea0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize  # Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96c99355-d423-4608-a7ad-ef6a81b20843",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_text = pd.Series(dataset['punct_text'].map(lambda x:word_tokenize(x.lower())), name=\"token_text\")\n",
    "# Here we use map function to trnasform each element of the column using our imported function word_tokenize\n",
    "# And save the new data into a series called token_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39699d66-1e30-42d1-8ea9-42ed5925fbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([dataset, token_text], axis=1)  # Joins a Dataframe and a Series to form a dataframe here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2f31de-177a-42b0-ab0f-1cb74187de4d",
   "metadata": {},
   "source": [
    "Lower case is important because it helps to maintain the consistency flow during the nlp tasks and text mining the lower() function makes the whole process straight forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ced366-b55e-468e-926b-1fdc1274fb63",
   "metadata": {},
   "source": [
    "### 3b.\n",
    "Then, printout the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f914554-8df8-4cb9-a853-3626d7362736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>punct_text</th>\n",
       "      <th>token_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nice song﻿</td>\n",
       "      <td>Nice song</td>\n",
       "      <td>[nice, song]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love song ﻿</td>\n",
       "      <td>I love song</td>\n",
       "      <td>[i, love, song]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love song ﻿</td>\n",
       "      <td>I love song</td>\n",
       "      <td>[i, love, song]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>860,000,000 lets make it first female to reach...</td>\n",
       "      <td>860000000 lets make it first female to reach o...</td>\n",
       "      <td>[860000000, lets, make, it, first, female, to,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shakira is best for worldcup﻿</td>\n",
       "      <td>shakira is best for worldcup</td>\n",
       "      <td>[shakira, is, best, for, worldcup]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The best world cup song ever!!!!﻿</td>\n",
       "      <td>The best world cup song ever</td>\n",
       "      <td>[the, best, world, cup, song, ever]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I love﻿</td>\n",
       "      <td>I love</td>\n",
       "      <td>[i, love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SEE SOME MORE SONG OPEN GOOGLE AND TYPE Shakir...</td>\n",
       "      <td>SEE SOME MORE SONG OPEN GOOGLE AND TYPE Shakir...</td>\n",
       "      <td>[see, some, more, song, open, google, and, typ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Awesome ﻿</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>[awesome]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I like shakira..﻿</td>\n",
       "      <td>I like shakira</td>\n",
       "      <td>[i, like, shakira]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             CONTENT  \\\n",
       "0                                         Nice song﻿   \n",
       "1                                      I love song ﻿   \n",
       "2                                      I love song ﻿   \n",
       "3  860,000,000 lets make it first female to reach...   \n",
       "4                      shakira is best for worldcup﻿   \n",
       "5                  The best world cup song ever!!!!﻿   \n",
       "6                                            I love﻿   \n",
       "7  SEE SOME MORE SONG OPEN GOOGLE AND TYPE Shakir...   \n",
       "8                                          Awesome ﻿   \n",
       "9                                  I like shakira..﻿   \n",
       "\n",
       "                                          punct_text  \\\n",
       "0                                          Nice song   \n",
       "1                                       I love song    \n",
       "2                                       I love song    \n",
       "3  860000000 lets make it first female to reach o...   \n",
       "4                       shakira is best for worldcup   \n",
       "5                       The best world cup song ever   \n",
       "6                                             I love   \n",
       "7  SEE SOME MORE SONG OPEN GOOGLE AND TYPE Shakir...   \n",
       "8                                           Awesome    \n",
       "9                                     I like shakira   \n",
       "\n",
       "                                          token_text  \n",
       "0                                       [nice, song]  \n",
       "1                                    [i, love, song]  \n",
       "2                                    [i, love, song]  \n",
       "3  [860000000, lets, make, it, first, female, to,...  \n",
       "4                 [shakira, is, best, for, worldcup]  \n",
       "5                [the, best, world, cup, song, ever]  \n",
       "6                                          [i, love]  \n",
       "7  [see, some, more, song, open, google, and, typ...  \n",
       "8                                          [awesome]  \n",
       "9                                 [i, like, shakira]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)  # Prints first ten rows of the dataframe by default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30396914-b67e-48da-a37c-aeb6f5adc9b0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5000f46-d87b-4408-a96f-08f9096b8439",
   "metadata": {},
   "source": [
    "## 4. Remove Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85a3006-86be-4c83-9594-a6bc8a52ec49",
   "metadata": {},
   "source": [
    "### 4a.\n",
    "Write a function to remove stopwords from “token_text” column in your data frame and save the cleaned text in a new column in your data frame called “nostop_text”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70f1b5f3-e87c-41a1-8149-759992308137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords  # Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37021fdc-ec0e-4379-bdce-6550cc30b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below we write a user defined function to remove stop words from a sentence\n",
    "def remove_stopwords(list_of_tokens):  # takes list as an input\n",
    "    filtered_words = [word for word in list_of_tokens if word not in stopwords.words('english')]\n",
    "    return filtered_words  # outputs the list after removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d97eb99-18fa-4d91-b2dd-286c0daf1e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "nostop_text = pd.Series(dataset['token_text'].map(lambda x:remove_stopwords(x)), name=\"nostop_text\")\n",
    "# Here we use map function to trnasform each element of the column using our user defined function\n",
    "# And save the new data into a series called nostop_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c488ad5-0b2c-4f6b-8547-73e4e9687799",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([dataset, nostop_text], axis=1)  # Joins a Dataframe and a Series to form a dataframe here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48923b25-1bf6-4ea7-93ab-ab46271b5cbe",
   "metadata": {},
   "source": [
    "### 4b.\n",
    "Then, printout the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ea1fd78-3ca7-4107-aad2-1e0654fae0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>punct_text</th>\n",
       "      <th>token_text</th>\n",
       "      <th>nostop_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nice song﻿</td>\n",
       "      <td>Nice song</td>\n",
       "      <td>[nice, song]</td>\n",
       "      <td>[nice, song]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love song ﻿</td>\n",
       "      <td>I love song</td>\n",
       "      <td>[i, love, song]</td>\n",
       "      <td>[love, song]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love song ﻿</td>\n",
       "      <td>I love song</td>\n",
       "      <td>[i, love, song]</td>\n",
       "      <td>[love, song]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>860,000,000 lets make it first female to reach...</td>\n",
       "      <td>860000000 lets make it first female to reach o...</td>\n",
       "      <td>[860000000, lets, make, it, first, female, to,...</td>\n",
       "      <td>[860000000, lets, make, first, female, reach, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shakira is best for worldcup﻿</td>\n",
       "      <td>shakira is best for worldcup</td>\n",
       "      <td>[shakira, is, best, for, worldcup]</td>\n",
       "      <td>[shakira, best, worldcup]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             CONTENT  \\\n",
       "0                                         Nice song﻿   \n",
       "1                                      I love song ﻿   \n",
       "2                                      I love song ﻿   \n",
       "3  860,000,000 lets make it first female to reach...   \n",
       "4                      shakira is best for worldcup﻿   \n",
       "\n",
       "                                          punct_text  \\\n",
       "0                                          Nice song   \n",
       "1                                       I love song    \n",
       "2                                       I love song    \n",
       "3  860000000 lets make it first female to reach o...   \n",
       "4                       shakira is best for worldcup   \n",
       "\n",
       "                                          token_text  \\\n",
       "0                                       [nice, song]   \n",
       "1                                    [i, love, song]   \n",
       "2                                    [i, love, song]   \n",
       "3  [860000000, lets, make, it, first, female, to,...   \n",
       "4                 [shakira, is, best, for, worldcup]   \n",
       "\n",
       "                                         nostop_text  \n",
       "0                                       [nice, song]  \n",
       "1                                       [love, song]  \n",
       "2                                       [love, song]  \n",
       "3  [860000000, lets, make, first, female, reach, ...  \n",
       "4                          [shakira, best, worldcup]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()  # Prints first ten rows of the dataframe by default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80631d5b-9c12-4329-86b4-6745602a5657",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9adbc3-c0ab-4379-81a5-e5f11435693d",
   "metadata": {},
   "source": [
    "## 5. Stem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0f4f9e-a01b-4bd4-a873-7bc175c9d3a5",
   "metadata": {},
   "source": [
    "### 5a.\n",
    "From NLTK PorterStemmer, use stem function in order to stem “nonstop_text”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "664eb788-5e22-4ac4-b43e-6e212177a7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer  # Importing libraries\n",
    "stemmer = PorterStemmer()  # Initailizing object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a038f0de-7dfa-482e-b48e-5d19b6206b79",
   "metadata": {},
   "source": [
    "### 5b.\n",
    "You may write a function to stem each word in “nonstop_text”. Then, save the stemmed text in a new column called “stemmed_text”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e378921b-235b-4260-8e10-96f1f0de01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below we write a user defined function to use porterstemmer for a list of words\n",
    "def porter_stemmer(plurals, stemmer):\n",
    "    singles = [stemmer.stem(plural) for plural in plurals]\n",
    "    return singles  # returns a list of words after converting them to their stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6827dfd3-f39c-449a-953f-5c5517ba055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_text = pd.Series(dataset['nostop_text'].map(lambda x:porter_stemmer(x, stemmer)), name=\"stemmed_text\")\n",
    "# Here we use map function to trnasform each element of the column using our user defined function\n",
    "# And save the new data into a series called stemmed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "686086fd-4848-418b-b773-92488ad8733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([dataset, stemmed_text], axis=1)  # Joins a Dataframe and a Series to form a dataframe here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fab51df-5feb-4dcc-902c-d9ce6cc0af57",
   "metadata": {},
   "source": [
    "### 5c.\n",
    "Printout the first few rows of your data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b972774-3770-4724-82b4-cd5f35958981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>punct_text</th>\n",
       "      <th>token_text</th>\n",
       "      <th>nostop_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nice song﻿</td>\n",
       "      <td>Nice song</td>\n",
       "      <td>[nice, song]</td>\n",
       "      <td>[nice, song]</td>\n",
       "      <td>[nice, song]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love song ﻿</td>\n",
       "      <td>I love song</td>\n",
       "      <td>[i, love, song]</td>\n",
       "      <td>[love, song]</td>\n",
       "      <td>[love, song]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love song ﻿</td>\n",
       "      <td>I love song</td>\n",
       "      <td>[i, love, song]</td>\n",
       "      <td>[love, song]</td>\n",
       "      <td>[love, song]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>860,000,000 lets make it first female to reach...</td>\n",
       "      <td>860000000 lets make it first female to reach o...</td>\n",
       "      <td>[860000000, lets, make, it, first, female, to,...</td>\n",
       "      <td>[860000000, lets, make, first, female, reach, ...</td>\n",
       "      <td>[860000000, let, make, first, femal, reach, on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shakira is best for worldcup﻿</td>\n",
       "      <td>shakira is best for worldcup</td>\n",
       "      <td>[shakira, is, best, for, worldcup]</td>\n",
       "      <td>[shakira, best, worldcup]</td>\n",
       "      <td>[shakira, best, worldcup]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             CONTENT  \\\n",
       "0                                         Nice song﻿   \n",
       "1                                      I love song ﻿   \n",
       "2                                      I love song ﻿   \n",
       "3  860,000,000 lets make it first female to reach...   \n",
       "4                      shakira is best for worldcup﻿   \n",
       "\n",
       "                                          punct_text  \\\n",
       "0                                          Nice song   \n",
       "1                                       I love song    \n",
       "2                                       I love song    \n",
       "3  860000000 lets make it first female to reach o...   \n",
       "4                       shakira is best for worldcup   \n",
       "\n",
       "                                          token_text  \\\n",
       "0                                       [nice, song]   \n",
       "1                                    [i, love, song]   \n",
       "2                                    [i, love, song]   \n",
       "3  [860000000, lets, make, it, first, female, to,...   \n",
       "4                 [shakira, is, best, for, worldcup]   \n",
       "\n",
       "                                         nostop_text  \\\n",
       "0                                       [nice, song]   \n",
       "1                                       [love, song]   \n",
       "2                                       [love, song]   \n",
       "3  [860000000, lets, make, first, female, reach, ...   \n",
       "4                          [shakira, best, worldcup]   \n",
       "\n",
       "                                        stemmed_text  \n",
       "0                                       [nice, song]  \n",
       "1                                       [love, song]  \n",
       "2                                       [love, song]  \n",
       "3  [860000000, let, make, first, femal, reach, on...  \n",
       "4                          [shakira, best, worldcup]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5f4d67-e04f-4975-b780-6916d8c3cfde",
   "metadata": {},
   "source": [
    "## 6. Lemmatize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b00fd8-1f20-4c9f-ab17-e3135ffad522",
   "metadata": {},
   "source": [
    "### 6a.\n",
    "From NLTK  WordNetLemmatizer, use lemmatize function to lemmatize “nonstop_text”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25520f60-20b9-4335-82fd-3949895d332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06c0b2b3-7429-4fff-8f9d-93004f29f2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dorai\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb3c68-425f-468e-b90f-ec16dcfd13b2",
   "metadata": {},
   "source": [
    "### 6b.\n",
    "You may write a function to lemmatize each word in “nonstop_text”. Then, save the lemmatized text in a new column called “lemmatized_text”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b45728de-1a7c-4588-b886-4e05b4bfa803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(word_list, wnl):\n",
    "    lemmatized_words = [wnl.lemmatize(w) for w in word_list]\n",
    "    return lemmatized_words  # returns a list of words after lemmatizing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4522a164-0ffa-4897-afc7-1029b48f507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_text = pd.Series(dataset['nostop_text'].map(lambda x:lemmatizer(x, wnl)), name=\"lemmatized_text\")\n",
    "# Here we use map function to trnasform each element of the column using our user defined function\n",
    "# And save the new data into a series called lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e08bd9d5-a979-4675-9cde-c42d81b97d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([dataset, lemmatized_text], axis=1)  # Joins a Dataframe and a Series to form a dataframe here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8e333a-a25f-456c-be69-51c033d639d6",
   "metadata": {},
   "source": [
    "### 6c.\n",
    "Printout the first few rows of your data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a2b0d06-0f22-4b70-b02f-aa7322fef30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>punct_text</th>\n",
       "      <th>token_text</th>\n",
       "      <th>nostop_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nice song﻿</td>\n",
       "      <td>Nice song</td>\n",
       "      <td>[nice, song]</td>\n",
       "      <td>[nice, song]</td>\n",
       "      <td>[nice, song]</td>\n",
       "      <td>[nice, song]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I love song ﻿</td>\n",
       "      <td>I love song</td>\n",
       "      <td>[i, love, song]</td>\n",
       "      <td>[love, song]</td>\n",
       "      <td>[love, song]</td>\n",
       "      <td>[love, song]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love song ﻿</td>\n",
       "      <td>I love song</td>\n",
       "      <td>[i, love, song]</td>\n",
       "      <td>[love, song]</td>\n",
       "      <td>[love, song]</td>\n",
       "      <td>[love, song]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>860,000,000 lets make it first female to reach...</td>\n",
       "      <td>860000000 lets make it first female to reach o...</td>\n",
       "      <td>[860000000, lets, make, it, first, female, to,...</td>\n",
       "      <td>[860000000, lets, make, first, female, reach, ...</td>\n",
       "      <td>[860000000, let, make, first, femal, reach, on...</td>\n",
       "      <td>[860000000, let, make, first, female, reach, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shakira is best for worldcup﻿</td>\n",
       "      <td>shakira is best for worldcup</td>\n",
       "      <td>[shakira, is, best, for, worldcup]</td>\n",
       "      <td>[shakira, best, worldcup]</td>\n",
       "      <td>[shakira, best, worldcup]</td>\n",
       "      <td>[shakira, best, worldcup]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             CONTENT  \\\n",
       "0                                         Nice song﻿   \n",
       "1                                      I love song ﻿   \n",
       "2                                      I love song ﻿   \n",
       "3  860,000,000 lets make it first female to reach...   \n",
       "4                      shakira is best for worldcup﻿   \n",
       "\n",
       "                                          punct_text  \\\n",
       "0                                          Nice song   \n",
       "1                                       I love song    \n",
       "2                                       I love song    \n",
       "3  860000000 lets make it first female to reach o...   \n",
       "4                       shakira is best for worldcup   \n",
       "\n",
       "                                          token_text  \\\n",
       "0                                       [nice, song]   \n",
       "1                                    [i, love, song]   \n",
       "2                                    [i, love, song]   \n",
       "3  [860000000, lets, make, it, first, female, to,...   \n",
       "4                 [shakira, is, best, for, worldcup]   \n",
       "\n",
       "                                         nostop_text  \\\n",
       "0                                       [nice, song]   \n",
       "1                                       [love, song]   \n",
       "2                                       [love, song]   \n",
       "3  [860000000, lets, make, first, female, reach, ...   \n",
       "4                          [shakira, best, worldcup]   \n",
       "\n",
       "                                        stemmed_text  \\\n",
       "0                                       [nice, song]   \n",
       "1                                       [love, song]   \n",
       "2                                       [love, song]   \n",
       "3  [860000000, let, make, first, femal, reach, on...   \n",
       "4                          [shakira, best, worldcup]   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0                                       [nice, song]  \n",
       "1                                       [love, song]  \n",
       "2                                       [love, song]  \n",
       "3  [860000000, let, make, first, female, reach, o...  \n",
       "4                          [shakira, best, worldcup]  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a355d39-5670-49d7-8568-f5cdbaa44129",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7bd66a-7eaa-4d79-8ac6-b5ffced3594e",
   "metadata": {},
   "source": [
    "## 7. Vectorizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d398d2-745a-4906-a7e6-0d1d7692c73b",
   "metadata": {},
   "source": [
    "### 7a.\n",
    "Import CountVectorizer from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e6f0dfe-6d04-41dc-b70f-61387810eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d2b295-e107-48a6-8e26-ae1399f2302a",
   "metadata": {},
   "source": [
    "### 7b., 7c.\n",
    "b.\tThen, instanciate CountVectorizer object.\n",
    "c.\tWithin CountVectorizer object you can set analyzer parameter to pass on your function from the previous steps to clean the text first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e6bcb15-641e-4ec7-a2c1-44ce4cbf85f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea76b0d-9452-44ff-bb48-9fea8d778706",
   "metadata": {},
   "source": [
    "### 7d.\n",
    "Within CountVectorizer object use fit_transform to vectorize the text and save it to counts_text (use either stemmed_text or lemmatized_text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8854ad6a-2d24-41a0-a469-8f9340c27ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_strings = pd.Series(dataset['lemmatized_text'].map(lambda x:' '.join(x)), name=\"lemmatized_strings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e873b56c-a463-41d4-9459-43f21ff736fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_text = vectorizer.fit_transform(lemmatized_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074ca96b-9064-49d1-9360-1a453bd991c9",
   "metadata": {},
   "source": [
    "### 7e.\n",
    "Print the number of rows and columns in counts_text and feature names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "718a8525-6c29-47c4-a229-83debb0130a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370, 1236)\n"
     ]
    }
   ],
   "source": [
    "print(counts_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6b005eb-12ae-48a6-aef9-69d9a929cf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['025', '0687119038', '10', '100', '1000000000', '100100', '105', '108k', '128gb', '13', '14', '15', '16gb', '17', '1855mm', '19', '1billiom', '1hmvtx', '1hmvtxbr', '1it', '1manband', '20', '200', '2004', '2010', '2013', '2015', '23', '25', '250', '2i', '3000', '32gb', '35', '3939life39s', '39cuz', '3d', '40', '4000', '421', '4500', '4gb', '4netjobscom', '4th', '50', '500', '5000', '50k', '55200mm', '600', '60inch', '682', '753', '860000000', '868', '97in', '9nlmemakemoneywithoutinvestment1', 'abominable', 'abomination', 'absolutely', 'absorbing', 'account', 'acidic', 'acquire', 'acquiring', 'act', 'actually', 'adam', 'addition', 'adele', 'adfly', 'admirable', 'adore', 'advertise', 'advertisement', 'advertisiments', 'affiliated', 'afflicted', 'africa', 'africabr', 'african', 'africanquot', 'africaquot', 'ago', 'agree', 'ahead', 'aid', 'air', 'aka', 'album', 'allinone', 'alot', 'already', 'also', 'alvar', 'always', 'amazed', 'amazement', 'amazing', 'amazon', 'ambition', 'ambitious', 'amendment', 'american', 'amiable', 'amount', 'amp', 'ampi', 'amy', 'ancestor', 'anderson', 'angel', 'animal', 'animation', 'animator', 'annoyed', 'annoying', 'another', 'anyone', 'anything', 'apostle', 'app', 'apple', 'appoints', 'appreciate', 'appreciated', 'apprecitate', 'approve', 'apps', 'arbitrate', 'around', 'artist', 'ask', 'assume', 'audit', 'aunt', 'autotuned', 'avicii39s', 'away', 'awesome', 'axiomatic', 'axy665', 'ba', 'baba', 'back', 'bad', 'ball', 'band', 'banging', 'bass', 'beautiful', 'beauty', 'become', 'begin', 'behavior', 'behold', 'belgium', 'believe', 'believerbr', 'beneath', 'best', 'bet', 'betfair', 'better', 'betterbr', 'beutiful', 'bieber', 'billion', 'bit', 'bitch', 'bitly14gkvdo', 'bitly1bsefqe', 'bitlymakemoneywithoutadroid', 'black', 'blank', 'blonde', 'bonus', 'bookie', 'bookmaker', 'boost', 'born', 'boxium', 'boy', 'br', 'brake', 'brazil', 'brazilian', 'bring', 'brinkman', 'british', 'brother', 'buck', 'bump', 'burder', 'business', 'button', 'buy', 'call', 'called', 'camera', 'camp', 'can39t', 'canal', 'capbr', 'car', 'card', 'cardsxbox', 'care', 'case', 'cause', 'cd', 'cease', 'celeb', 'celebrated', 'celebration3939', 'celebrity', 'cent', 'cge', 'chance', 'change', 'channel', 'channelbr', 'channnnnnelll', 'chap', 'charity', 'chaste', 'check', 'chill', 'choice', 'christ', 'christian', 'claiming', 'clap', 'classproflink', 'classproflinkprefixspana', 'classproflinkwrapperspan', 'claster', 'click', 'close', 'closer', 'co', 'coby', 'cock', 'code', 'colorful', 'colour', 'columbus', 'com', 'come', 'comedy', 'comfort', 'comforter', 'coming', 'comment', 'commit', 'company', 'compared', 'complete', 'completely', 'comprehend', 'conceived', 'conciliate', 'confessor', 'congress', 'conhece', 'constitution', 'consumer', 'contact', 'continue', 'convinced', 'cool', 'core', 'costfree', 'couch', 'could', 'counsel', 'countless', 'country', 'courtthanks', 'cover', 'crank', 'crazy', 'creator', 'crestboot', 'cup', 'curly', 'currently', 'cute', 'cutie', 'cyrus', 'd90', 'da', 'daily', 'damn', 'dance', 'dancer', 'dancing', 'daneja', 'dark', 'day', 'de', 'deal', 'decided', 'dedication', 'definitely', 'definitily', 'definitley', 'del', 'delete', 'demonstrating', 'describes', 'design', 'dickwad', 'different', 'dis', 'discrimination', 'discus', 'disguisequot', 'dislike', 'disliked', 'divine', 'doesn39t', 'dollar', 'don39t', 'donate', 'donating', 'done', 'dont', 'dot', 'download', 'dragon', 'dragonsand', 'drake', 'dream', 'dreamer', 'dreaming', 'dribbleproshot', 'drive', 'drum', 'dubstep', 'duzafizz', 'earn', 'earning', 'earth', 'easily', 'easy', 'echa', 'edge', 'edm', 'effort', 'egoistic', 'eh', 'eight', 'ej', 'em39', 'email', 'empirebr', 'enabled', 'enjoy', 'enjoyable', 'enlace', 'enlist', 'enormously', 'enter', 'entertainer', 'especially', 'estiloproduction', 'estonia', 'euro', 'euw', 'eva', 'even', 'event', 'ever', 'everbr', 'every', 'everyday', 'everyone', 'everything', 'evidence', 'evil', 'exact', 'expect', 'expecting', 'experience', 'expose', 'extraordinary', 'facebook', 'facebooktwitter', 'family', 'famine', 'famous', 'fan', 'fantastic', 'far', 'fast', 'fausto', 'fave', 'faves', 'favourite', 'fear', 'featuring', 'feed', 'feel', 'felt', 'female', 'fiddle', 'fifa', 'fight', 'fighting', 'filibuster', 'financial', 'find', 'finding', 'firepacom', 'first', 'floor', 'focus', 'following', 'food', 'foot', 'football', 'footballsoccer', 'forever', 'forget', 'forgetful', 'forgot', 'form', 'forty', 'forward', 'found', 'founded', 'foward', 'fr', 'fragile', 'france', 'free', 'freedom', 'freestyle', 'french', 'frequent', 'friend', 'fright', 'frndzzl', 'fuck', 'fucking', 'fun', 'future', 'fyi', 'gain', 'gained', 'galaxy', 'game', 'gamezz', 'gamezzmta', 'gangnam', 'gardner', 'gave', 'gen', 'generated', 'generation', 'germany', 'get', 'getting', 'gift', 'girl', 'give', 'giving', 'gmailcom', 'go', 'goal', 'god', 'going', 'gon', 'good', 'google', 'goood', 'goose', 'gorgeous', 'got', 'grace', 'grass', 'great', 'gt', 'gta', 'gtgt', 'guess', 'guide', 'guitar', 'guruofmovie', 'gusttavo', 'guy', 'guysi', 'gypsy', 'haha', 'hahahahah', 'hair', 'half', 'halloween', 'hand', 'happen', 'happening', 'happy', 'hard', 'harder', 'hasbr', 'hate', 'hdtv', 'hear', 'heard', 'hearing', 'heaven', 'hell', 'hello', 'help', 'hey', 'hhnl', 'hi', 'hi5', 'hicheck', 'high', 'highly', 'hilarious', 'hip', 'hiring', 'historical', 'hit', 'holy', 'home', 'honest', 'hope', 'hopefully', 'hopme', 'horse', 'hot', 'hour', 'houronly', 'house', 'hrefhttpadflyhttpadflya', 'hrefhttpithtithta', 'hrefhttpsplusgooglecom101721377578919894134', 'hrefhttpswwwpaidvertscomrefmarius1533httpswwwpaidvertscomrefmarius1533a', 'hrefhttpswwwpaidvertscomrefsihaam01httpswwwpaidvertscomrefsihaam01a', 'hrefhttpswwwyoutubecomwatchvprpeedmmmq0httpswwwyoutubecomwatchvprpeedmmmq0a', 'hrefhttpwwwthepetitionsitecom387433550stopanimaltraffickingcidheaderclickhttpwwwthepetitionsitecom387433550stopanimaltraffickingcidheaderclicka', 'hrefhttpwwwyoutubecomwatchvprpeedmmmq0ampt1m00s100a', 'huge', 'humanity', 'i39ll', 'i39m', 'i39ve', 'i5', 'ice', 'ik', 'ill', 'ilove', 'ilovethissong', 'im', 'im2458444', 'imagine', 'immediately', 'importantly', 'impossible', 'improve', 'incandescent', 'including', 'income', 'incomeonly', 'incredible', 'independent', 'industry', 'info', 'iniesta39s', 'innocent', 'inspire', 'instantly', 'instead', 'instrumental', 'insurance', 'intel', 'intention', 'investmentjust', 'inviolate', 'ipad', 'iphone', 'irish', 'isn39t', 'it39d', 'it39s', 'itbr', 'itquot', 'itt', 'itttttttt', 'iv', 'ive', 'jawan', 'jesus', 'jim', 'job', 'johnny', 'join', 'joining', 'juno', 'justice', 'justien', 'katy', 'keep', 'keyboard', 'kid', 'killed', 'killing', 'killtheclockhd', 'kind', 'kld3y', 'kluivert', 'know', 'kodaline', 'kpop', 'la', 'lad', 'lake', 'lame', 'lamest', 'lana', 'land', 'language', 'large', 'later', 'latest', 'laugh', 'learn', 'least', 'led', 'leeched', 'left', 'leisure', 'let', 'lie', 'life', 'like', 'likeampsubscribe', 'likebr', 'likedbr', 'liking', 'lima', 'line', 'link', 'lip', 'lisening', 'listen', 'listenersupported', 'listening', 'live', 'lively', 'lol', 'long', 'look', 'lord', 'loss', 'lot', 'love', 'loved', 'lovely', 'lover39s', 'loving', 'loyal', 'lt3', 'lt3br', 'luxury', 'macabre', 'macbook', 'macklemore', 'made', 'madly', 'make', 'making', 'man39s', 'many', 'marketer', 'martin', 'martyr', 'mary', 'master', 'mate', 'matter', 'maybe', 'mean', 'meaning', 'meaningful', 'meat', 'medium', 'meet', 'meh', 'memory', 'men', 'mess', 'message', 'mi', 'might', 'miley', 'mileycelebnewscouk', 'mileysecretvideocouk', 'million', 'millionsbr', 'min', 'mind', 'mini', 'minute', 'mio', 'miss', 'mississippi', 'miusic', 'mixtape', 'mixtapecheck', 'model', 'moment', 'money', 'moneygqcom', 'moneyquot', 'month', 'monthly', 'morning', 'mother', 'motherlandbr', 'movement', 'mta', 'much', 'muchshakira', 'murder', 'music', 'musicbr', 'musician', 'musiclyrics', 'musicvideo', 'muslim', 'must', 'na', 'name', 'name39s', 'named', 'namepicture', 'nation', 'need', 'needed', 'neeru105', 'neighbor', 'netherland', 'netherlands', 'never', 'new', 'newest', 'news', 'nice', 'nicely', 'nick', 'night', 'nikon', 'none', 'northland', 'nothing', 'nsa', 'number', 'numberless', 'nummber', 'não', 'obtain', 'offical', 'oh', 'oid101721377578919894134shakiravevoaspan', 'old', 'oldchattk', 'omg', 'one', 'online', 'open', 'openly', 'opportunity', 'original', 'others', 'ouf', 'ouffffffffffffffffff', 'ourself', 'page', 'pagee', 'paid', 'paranormal', 'parody', 'part', 'partyman318', 'pas', 'passed', 'passionate', 'passionbr', 'past', 'patriarch', 'patrik', 'patriot', 'paul', 'pay', 'pc', 'peace', 'peaceful', 'people', 'pepelexa', 'per', 'perfect', 'perform', 'perhaps', 'perry', 'person', 'perverse', 'petitionbr', 'piano', 'pink', 'piss', 'plausible', 'play', 'player', 'playerhis', 'playerto', 'playlist', 'plea', 'pleasant', 'please', 'plot', 'plus', 'plz', 'plzz', 'poor', 'population', 'porno', 'portugal', 'possiblequot', 'posted', 'postponing', 'ppl', 'prank', 'pray', 'prepare', 'present', 'press', 'pretty', 'price320', 'price360', 'price385', 'price390', 'price510', 'price515', 'prior', 'privacy', 'pro', 'probably', 'producer', 'profile', 'promise', 'promotes', 'prophet', 'protect', 'protest', 'proud', 'prove', 'ps4', 'psn', 'purchase', 'pure', 'push', 'put', 'quality', 'queen', 'quid', 'quot', 'quotdribbleproshotquot', 'quothelp', 'quoti39m', 'quotnoquot', 'quotthis', 'quotthumbs', 'quotversace', 'quotwake', 'quotwe', 'quotyeahquot', 'quotyour', 'racist', 'raise', 'rand', 'range', 'rapper', 'rappersinger', 'rate', 'reach', 'read', 'reading', 'real', 'realized', 'really', 'reason', 'recipe', 'recognizes', 'recommend', 'record', 'recording', 'redeemer', 'reed', 'refused', 'regret', 'remember', 'remezcla', 'remix', 'renewal', 'repay', 'replay', 'requite', 'respond', 'reveling', 'rey', 'richest', 'ricky', 'right', 'righteousness', 'risk', 'roar', 'rocksbr', 'roll', 'rosary', 'roughly', 'rugby', 'rule', 's4', 'sad', 'said', 'saint', 'salvation', 'sam', 'samebr', 'samsung', 'saturday', 'saved', 'savior', 'say', 'saying', 'search', 'seat', 'second', 'secret', 'secure', 'see', 'seem', 'seen', 'selecting', 'senate', 'senator', 'send', 'sexy', 'shaki', 'shakifans', 'shakira', 'shakira39s', 'shakirabr', 'shakiralt33333', 'shakiria', 'shall', 'shame', 'share', 'she39s', 'shit', 'shkira', 'shot', 'sign', 'significantly', 'sillyquot', 'simple', 'simply', 'sin', 'sing', 'singer', 'singing', 'singlewave', 'sinned', 'sister', 'site', 'skill', 'skin', 'skip', 'slr', 'small', 'smart', 'smh', 'smoking', 'soccer', 'social', 'society', 'someone', 'something', 'son', 'song', 'songwriter', 'sony', 'soo', 'soon', 'sooooo', 'sorry', 'sound', 'south', 'space', 'spain', 'spam', 'spamming', 'span', 'spanish', 'spare', 'speaks', 'special', 'speech', 'spending', 'spent', 'spirit', 'spourmo', 'spread', 'spying', 'stand', 'start', 'started', 'statement', 'step', 'steven', 'stil', 'still', 'stop', 'store', 'strategizes', 'street', 'stretch', 'student', 'style', 'sub', 'submits', 'subscribe', 'subscribed', 'subscribeeeeeeeeee', 'subscriber', 'subscribing', 'subscription', 'substantially', 'succeeds', 'successcheers', 'successful', 'suck', 'sucking', 'summer', 'super', 'support', 'supreme', 'sure', 'survey', 'suscribe', 'suscribite', 'suscríbase', 'swagfriends', 'swear', 'swim', 'synch', 'taaeecom', 'take', 'talking', 'tan', 'tape', 'team', 'technique', 'teenage', 'tell', 'terrible', 'terrorism', 'terrorist', 'thank', 'thanks', 'thankyou', 'that39d', 'that39s', 'there', 'thergloveblogspotin201308blogpost_10html', 'thing', 'thingsbr', 'think', 'thisbr', 'thousand', 'three', 'thumb', 'thumsb', 'thus', 'time', 'tinyurldotcomslashmxh2y77', 'today', 'together', 'took', 'top', 'torunament', 'totally', 'town', 'trade', 'trafficking', 'transformed', 'transport', 'trayvon', 'tried', 'true', 'truly', 'trumpetcallofgodonline', 'truth', 'trying', 'tube', 'tunez', 'turned', 'tvcmcadavidweebly', 'twitter', 'two', 'type', 'ultrabooks', 'un', 'uncle', 'undefiled', 'underrated', 'understand', 'unique', 'unit', 'united', 'unlocked', 'upquot', 'upto', 'useful', 'usl', 'vaio', 'vanstone', 'versace', 'version', 'vibe39s', 'video', 'videosbr', 'vids', 'view', 'viewsbr', 'vincent', 'vine', 'virgin', 'visit', 'vistazo', 'você', 'voice', 'vote', 'voucher', 'vídeo', 'wafence', 'wager', 'waka', 'wakad', 'wake', 'wallet', 'wan', 'wanderfol', 'want', 'wasn39t', 'wasting', 'watch', 'watched', 'watching', 'watchv5tu9gn1l310', 'watchvdtqcftr1fac', 'wats', 'way', 'way39s', 'we39re', 'web', 'website', 'week', 'weird', 'well', 'wellcomemdblogfacom', 'wery', 'whats', 'whatuknow', 'white', 'whitney', 'who39s', 'whole', 'wholehearted', 'whose', 'wickedness', 'wide', 'wifi4g', 'wil', 'willing', 'wilsubscribe', 'win', 'winner', 'winooze', 'wiredo', 'wish', 'without', 'wk', 'woman', 'womanly', 'won39t', 'wont', 'wooooo', 'word', 'work', 'working', 'world', 'worldcup', 'worried', 'worth', 'would', 'wow', 'wow5', 'wrecking', 'write', 'writer', 'wurkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk', 'ww', 'x3333333333', 'xxx', 'y39all', 'ya', 'yall', 'ybuwyn', 'yea', 'year', 'yearsbr', 'yet', 'you39re', 'youtube', 'youtubebr', 'youtubecentral', 'youtubers', 'zealous', 'zonepacom', 'ｈｔｔｐｗｗｗｅｂａｙｃｏｍｕｓｒｓｈｏｅｃｏｌｌｅｃｔｏｒ314']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ae8656-1b62-4bc6-acd9-ab9e585e421d",
   "metadata": {},
   "source": [
    "### 7f.\n",
    "Wihtin CountVectorizer set ngram_range parameter such that only two adjacent words are being vectorized in the text (use either stemmed_text or lemmatized_text) and save the result into ngramcounts_text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1928af79-8ca4-448c-bc03-72e87b65398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer2 = CountVectorizer(ngram_range=(2, 2))  # here (2,2) tuple is used\n",
    "ngramcounts_text = vectorizer2.fit_transform(lemmatized_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447e683d-bd44-416f-930d-66ac55938faa",
   "metadata": {},
   "source": [
    "### 7g.\n",
    "Print the number of rows and columns in ngramcounts_text and feature names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f356ce7c-cf15-45cd-b55b-ec0e347ddbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370, 2225)\n"
     ]
    }
   ],
   "source": [
    "print(ngramcounts_text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "37c96df3-bc89-480a-8c01-d49102b207dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['025 free', '0687119038 nummber', '10 cent', '100 listenersupported', '100 million', '1000000000 time', '105 hour', '108k people', '128gb price515', '13 intel', '14 15', '14 year', '15 goal', '15 ps4', '15 year', '16gb new', '17 rappersinger', '1855mm 55200mm', '19 year', '1billiom view', '1hmvtxbr delete', '1it africa', '1manband music', '20 fifa', '20 minute', '200 galaxy', '200 visit', '2004 check', '2010 im', '2013 likeampsubscribe', '2015 hi5', '2015 like', '23 world', '25 35', '250 ipad', '2i born', '3000 per', '32gb black', '32gb price390', '32gb unlocked', '35 hour', '35 houronly', '3939life39s celebration3939', '39cuz quotyeahquot', '3d led', '40 hour', '4000 5000', '421 gangnam', '4500 buck', '4gb 128gb', '4netjobscom work', '4th amendment', '4th gen', '50 million', '500 like', '500 quid', '500 subscriber', '5000 monthly', '50k per', '55200mm 32gb', '600 quid', '60inch 3d', '682 421', '753 682', '860000000 let', '868 mio', '97in white', 'abominable generation', 'abomination clap', 'absolutely adore', 'absolutely fantastic', 'absorbing macabre', 'account subscribing', 'account wont', 'acidic stretch', 'acquire bonus', 'acquiring bonus', 'act renewal', 'actually high', 'actually work', 'adam whitney', 'addition design', 'adele kodaline', 'adfly kld3y', 'admirable pray', 'adore watching', 'advertise channel', 'advertise simple', 'advertisement chance', 'advertisement incredible', 'advertisiments chance', 'affiliated company', 'afflicted pray', 'africa 2i', 'africa african', 'africa br', 'africa check', 'africa mean', 'africa shame', 'africa wasn39t', 'africabr br', 'african colour', 'african people', 'africanquot go', 'africaquot one', 'ago ancestor', 'ago damn', 'agree like', 'ahead roughly', 'aid event', 'air price320', 'aka soccer', 'album click', 'allinone pc', 'alot learn', 'already know', 'also ive', 'also passionate', 'also refused', 'also start', 'also type', 'alvar lake', 'always give', 'always goose', 'amazed hope', 'amazement team', 'amazing love', 'amazing song', 'amazon gift', 'ambition dedication', 'ambitious winooze', 'amendment right', 'american un', 'amiable pray', 'amount view', 'amount would', 'amp 100', 'amp enjoy', 'amp keyboard', 'amp like', 'amp passionbr', 'amp play', 'amp spare', 'amp you39re', 'ampi love', 'amy music', 'ancestor left', 'anderson i39m', 'angel pray', 'animal trafficking', 'animation industry', 'animator trying', 'annoyed please', 'annoying hell', 'another account', 'anyone annoyed', 'anyone br', 'anyone get', 'anyone importantly', 'anyone listen', 'anyone real', 'anything get', 'apostle pray', 'app app', 'app complete', 'app let', 'app store', 'apple ipad', 'apple iphone', 'apple macbook', 'appoints roll', 'appreciate take', 'appreciate took', 'appreciated thumb', 'approve axiomatic', 'apps get', 'arbitrate guide', 'around facebook', 'artist reach', 'ask nicely', 'assume bookmaker', 'audit frequent', 'aunt love', 'avicii39s wake', 'away thank', 'awesome cover', 'awesome day', 'awesome entertainer', 'awesome it39d', 'awesome sound', 'axiomatic insurance', 'ba dancing', 'baba brinkman', 'bad brazilian', 'bad choice', 'bad happening', 'bad meaning', 'ball house', 'ball vincent', 'band page', 'banging today', 'bass cover', 'bass drum', 'beautiful american', 'beautiful girl', 'beautiful lovely', 'beautiful song', 'beautiful south', 'become famous', 'become first', 'begin work', 'behavior grass', 'behold murder', 'belgium spain', 'believe jesus', 'believe soccer', 'believe website', 'believerbr br', 'beneath mileysecretvideocouk', 'best dancer', 'best ever', 'best fifa', 'best one', 'best singer', 'best song', 'best voice', 'best way', 'best website', 'best wk', 'best world', 'best worldcup', 'bet betfair', 'betfair acquire', 'betfair secure', 'better 39cuz', 'better football', 'better footballsoccer', 'betterbr katy', 'bieber car', 'billion replay', 'billion share', 'billion viewsbr', 'bit blank', 'black price385', 'blank space', 'bonus deal', 'bonus income', 'bookie pay', 'bookmaker bet', 'bookmaker pay', 'bookmaker put', 'boost football', 'born beautiful', 'boxium womanly', 'boy dreaming', 'boy trying', 'boy want', 'br axy665', 'br br', 'br can39t', 'br check', 'br could', 'br dance', 'br don39t', 'br empirebr', 'br help', 'br hrefhttpadflyhttpadflya', 'br im', 'br like', 'br love', 'br read', 'br waka', 'br way39s', 'br world', 'br would', 'brake thingsbr', 'brazil please', 'bring change', 'bring memory', 'brinkman song', 'british called', 'british don39t', 'brother sister', 'buck monthly', 'bump part', 'burder colorful', 'business senator', 'buy postponing', 'buy subscriber', 'call instrumental', 'called firepacom', 'called juno', 'called moneygqcom', 'called quoti39m', 'called quotwe', 'called rugby', 'called soccer', 'called wan', 'called zonepacom', 'camera 1855mm', 'camera nikon', 'camp time', 'can39t comprehend', 'can39t experience', 'can39t remember', 'canal de', 'car 2013', 'card even', 'card free', 'card voucher', 'cardsxbox live', 'care nation', 'case instead', 'case land', 'case want', 'cause know', 'cd couch', 'cease reveling', 'celeb site', 'celebrated openly', 'celebration3939 peace', 'celebrity website', 'cent also', 'cge quotversace', 'chance amount', 'chance describes', 'chance getting', 'chance ill', 'chance mean', 'chance please', 'chance prove', 'chance really', 'chance won39t', 'change life', 'change together', 'channel alvar', 'channel check', 'channel comment', 'channel could', 'channel cover', 'channel gamezzmta', 'channel get', 'channel i39ve', 'channel ik', 'channel love', 'channel lt3', 'channel real', 'channel recording', 'channel subscribe', 'channel suscribite', 'channel thanks', 'channel watch', 'channnnnnelll plzz', 'chap named', 'charity case', 'chaste pray', 'check amy', 'check animal', 'check awesome', 'check baba', 'check band', 'check bass', 'check celebrity', 'check channel', 'check comedy', 'check cover', 'check daneja', 'check dubstep', 'check extraordinary', 'check fragile', 'check girl', 'check gt', 'check irish', 'check lake', 'check meat', 'check mother', 'check music', 'check new', 'check original', 'check page', 'check partyman318', 'check peaceful', 'check plausible', 'check playlist', 'check remix', 'check send', 'check share', 'check statement', 'check swagfriends', 'check video', 'choice br', 'choice shakira', 'christ pray', 'christ saved', 'christ savior', 'christian pray', 'claiming bonus', 'clap hand', 'classproflink hrefhttpsplusgooglecom101721377578919894134', 'classproflinkprefixspana classproflink', 'classproflinkwrapperspan classproflinkprefixspana', 'claster incandescent', 'click away', 'click bitlymakemoneywithoutadroid', 'click enlace', 'click hrefhttpswwwpaidvertscomrefsihaam01httpswwwpaidvertscomrefsihaam01a', 'click link', 'click namepicture', 'close hit', 'closer dream', 'coby usl', 'cock wish', 'code im2458444', 'colorful claster', 'colour skin', 'columbus mississippi', 'com dont', 'com make', 'com quot', 'com spread', 'come channel', 'come spam', 'comedy recipe', 'comfort home', 'comforter afflicted', 'comment comment', 'comment everyone', 'comment expose', 'comment get', 'comment hearing', 'comment like', 'comment likebr', 'comment maybe', 'comment music', 'comment still', 'comment subscribe', 'comment thanks', 'comment video', 'commit abomination', 'company think', 'compared million', 'complete survey', 'completely independent', 'completely made', 'comprehend miley', 'conceived without', 'conciliate acidic', 'confessor pray', 'congress men', 'conhece br', 'constitution buy', 'constitution matter', 'constitution nation', 'consumer yet', 'contact neeru105', 'continue reading', 'convinced girl', 'cool best', 'cool new', 'cool song', 'core i5', 'costfree guess', 'couch song', 'could 108k', 'could listen', 'could please', 'could press', 'could spanish', 'could spare', 'could take', 'could visit', 'could would', 'counsel pray', 'countless others', 'country strategizes', 'cover account', 'cover avicii39s', 'cover channel', 'cover check', 'cover don39t', 'cover dont', 'cover feel', 'cover give', 'cover hip', 'cover like', 'cover miley', 'cover piano', 'cover please', 'cover say', 'crank call', 'creator pray', 'crestboot boxium', 'cup offical', 'cup song', 'currently hiring', 'cute blonde', 'cutie girl', 'cyrus actually', 'cyrus done', 'cyrus imagine', 'cyrus secret', 'cyrus wrecking', 'd90 slr', 'da channel', 'daily gt', 'daily vine', 'dance search', 'dance sing', 'daneja good', 'dark horse', 'day everyday', 'day make', 'day night', 'de youtube', 'deal weird', 'decided watch', 'dedication amp', 'definitely look', 'definitily amazed', 'definitley song', 'del rey', 'delete space', 'demonstrating right', 'describes rate', 'design worried', 'dickwad we39re', 'different good', 'different happy', 'dis song', 'discrimination tinyurldotcomslashmxh2y77', 'discrimination united', 'discus successful', 'dislike song', 'divine grace', 'doesn39t please', 'doesn39t talking', 'dollar poor', 'don39t agree', 'don39t forget', 'don39t lie', 'don39t money', 'don39t need', 'don39t think', 'donate give', 'donate thanks', 'donating dollar', 'done cover', 'done shakira', 'done today', 'dont miss', 'dont money', 'dot com', 'download app', 'download free', 'dragon lana', 'dragonsand please', 'drake macklemore', 'dream huge', 'dream thank', 'dreamer one', 'dreaming successful', 'dribbleproshot search', 'drive crazy', 'drum amp', 'dubstep version', 'duzafizz singlewave', 'earn lot', 'earn money', 'earning income', 'earth recognizes', 'earth seen', 'easily make', 'easily spending', 'easy enjoyable', 'easy money', 'echa un', 'edm remix', 'effort bitly14gkvdo', 'egoistic 23', 'eh eh', 'eight year', 'ej ba', 'em39 coming', 'email senator', 'empirebr br', 'enabled give', 'enjoy making', 'enjoy music', 'enjoyable info', 'enlace suscríbase', 'enlist person', 'enormously improve', 'enter music', 'entertainer pretty', 'especially future', 'estiloproduction com', 'estonia please', 'euro money', 'euw germany', 'even amazon', 'even millionsbr', 'event something', 'ever 0687119038', 'ever get', 'ever time', 'ever x3333333333', 'everbr thumb', 'every form', 'every time', 'everyday join', 'everyday shakifans', 'everyone anyone', 'everyone good', 'everyone intention', 'everyone know', 'everyone name39s', 'everyone right', 'everyone see', 'everything bad', 'evidence facebook', 'evil leisure', 'evil neighbor', 'exact enjoy', 'expect world', 'expecting buy', 'experience begin', 'experience luxury', 'expose musicbr', 'extraordinary website', 'facebook lame', 'facebook northland', 'facebook old', 'facebook support', 'facebook twitter', 'facebooktwitter youtube', 'family pray', 'famine i39ll', 'famous inspire', 'fan really', 'fantastic chance', 'fantastic love', 'far costfree', 'far free', 'fast paid', 'fausto substantially', 'fave song', 'faves xxx', 'favourite singer', 'fear appoints', 'fear none', 'featuring best', 'feel free', 'feel like', 'felt old', 'female artist', 'female hit', 'female reach', 'fiddle player', 'fiddle sillyquot', 'fifa 14', 'fifa 15', 'fifa world', 'fight 4th', 'fight protect', 'fight rand', 'fighting constitution', 'filibuster fighting', 'financial risk', 'find useful', 'finding wager', 'firepacom check', 'firepacom make', 'firepacom visit', 'first female', 'first song', 'floor protest', 'focus quality', 'following youtube', 'food social', 'foot called', 'football aka', 'football also', 'football foot', 'football plus', 'football skill', 'football soccer', 'footballsoccer playerto', 'forever whole', 'forget br', 'forget song', 'forget subscribe', 'forgetful pepelexa', 'forgot everything', 'form evil', 'forty hour', 'forward second', 'found app', 'found way', 'founded join', 'foward day', 'fr good', 'fragile swim', 'france portugal', 'free apps', 'free assume', 'free comment', 'free gift', 'free simply', 'free video', 'free website', 'freedom justice', 'freedom speech', 'freestyle get', 'french kpop', 'frequent son', 'friend everyday', 'friend love', 'friend sam', 'frndzzl subscribe', 'fuck best', 'fucking bitch', 'fucking video', 'fun it39s', 'future believe', 'fyi isn39t', 'gain voice', 'gained god', 'galaxy s4', 'game please', 'gamezz mta', 'gangnam style', 'gardner help', 'gave chance', 'gen 32gb', 'generated 600', 'generation shall', 'germany netherland', 'get 500', 'get better', 'get free', 'get money', 'get moneyquot', 'get music', 'get new', 'get old', 'get paid', 'getting gorgeous', 'getting heard', 'gift card', 'girl beautiful', 'girl check', 'girl hot', 'girl name', 'girl work', 'give chance', 'give chill', 'give email', 'give one', 'give thumb', 'give working', 'giving food', 'go billion', 'go channel', 'go check', 'go da', 'go heaven', 'go learn', 'go see', 'go shaki', 'go web', 'goal isn39t', 'goal netherlands', 'goal watch', 'god go', 'god hot', 'god pray', 'god righteousness', 'god sexy', 'going call', 'gon na', 'good artist', 'good counsel', 'good girl', 'good go', 'good song', 'good spirit', 'good time', 'good tunez', 'good way', 'google generated', 'google gtgt', 'google ive', 'google steven', 'google type', 'google web', 'google website', 'goose bump', 'gorgeous definitely', 'gorgeous fiddle', 'gorgeous hair', 'got alot', 'got go', 'grace pray', 'grass check', 'great second', 'gt hrefhttpswwwpaidvertscomrefmarius1533httpswwwpaidvertscomrefmarius1533a', 'gt swagfriends', 'gta 20', 'gtgt 9nlmemakemoneywithoutinvestment1', 'guess bookie', 'guess skip', 'guide addition', 'guitar bass', 'gusttavo lima', 'guy check', 'guy cover', 'guy girl', 'guy love', 'guy whats', 'guysi found', 'gypsy shakira', 'haha good', 'haha miley', 'hahahahah like', 'hair way', 'half second', 'halloween video', 'hand wickedness', 'happy instantly', 'happy time', 'hard working', 'harder anyone', 'hasbr meaningful', 'hate behold', 'hdtv price510', 'hear amp', 'hear haha', 'hear original', 'hear rapper', 'hear song', 'hear word', 'heard dribbleproshot', 'heard nothing', 'heard please', 'heard thank', 'heard year', 'hearing song', 'heaven believe', 'heaven forever', 'hell sorry', 'hello everyone', 'hello guysi', 'help also', 'help christian', 'help earn', 'help push', 'help rand', 'help reach', 'help record', 'help shakira', 'help shakira39s', 'hey check', 'hey dickwad', 'hey don39t', 'hey forty', 'hey guy', 'hey hit', 'hey music', 'hey tried', 'hey youtubers', 'hi check', 'hi everyone', 'hi heard', 'hi johnny', 'hi nice', 'hicheck share', 'high profile', 'highly appreciated', 'hilarious tube', 'hip don39t', 'hiring people', 'historical shame', 'hit 1billiom', 'hit replay', 'hit shit', 'holy mary', 'holy mother', 'holy rosary', 'holy virgin', 'home business', 'home currently', 'home enabled', 'home stop', 'home today', 'honest there', 'hope everyone', 'hope help', 'hopefully work', 'hopme click', 'horse ahead', 'hour 4netjobscom', 'hour famine', 'hour i39m', 'hour senate', 'houronly 4netjobscom', 'house edm', 'hrefhttpadflyhttpadflya 1hmvtx', 'hrefhttpadflyhttpadflya 1hmvtxbr', 'hrefhttpithtithta privacy', 'hrefhttpsplusgooglecom101721377578919894134 oid101721377578919894134shakiravevoaspan', 'hrefhttpswwwpaidvertscomrefsihaam01httpswwwpaidvertscomrefsihaam01a it39s', 'hrefhttpwwwyoutubecomwatchvprpeedmmmq0ampt1m00s100a passed', 'huge one', 'huge youtube', 'humanity sign', 'i39ll giving', 'i39ll promise', 'i39ll sub', 'i39ll subscribe', 'i39ll work', 'i39m 15', 'i39m 1manband', 'i39m hard', 'i39m raise', 'i39m singer', 'i39ve cover', 'i39ve decided', 'i39ve done', 'i5 4gb', 'ice audit', 'ik yall', 'ill make', 'ilove shakira', 'im 17', 'im instrumental', 'im left', 'im listening', 'im rapper', 'im still', 'im2458444 also', 'imagine dragon', 'imagine dragonsand', 'immediately easily', 'importantly focus', 'impossible say', 'improve soccer', 'incandescent ambitious', 'including quotyour', 'income chap', 'income financial', 'income lad', 'income risk', 'incomeonly 4netjobscom', 'incredible music', 'independent amp', 'industry maybe', 'industry please', 'info contact', 'iniesta39s goal', 'innocent day', 'inspire fyi', 'instantly make', 'instead proud', 'instrumental songwriter', 'insurance fear', 'intel core', 'intention spam', 'investmentjust visit', 'inviolate pray', 'ipad 200', 'ipad 4th', 'iphone latest', 'irish guy', 'isn39t become', 'isn39t spamming', 'it39d mean', 'it39s click', 'it39s easy', 'it39s fun', 'it39s real', 'it39s time', 'it39s work', 'itbr br', 'itquot thank', 'itquot thanks', 'itt ppl', 'itttttttt wurkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkkk', 'iv 16gb', 'ive made', 'ive started', 'jawan gardner', 'jesus christ', 'jim vanstone', 'job site', 'johnny already', 'join fight', 'join movement', 'join new', 'join rand', 'joining fright', 'juno wallet', 'justice line', 'justien bieber', 'katy bad', 'katy perry', 'keep em39', 'keep getting', 'keyboard i39m', 'kid hey', 'killed versace', 'killing anyone', 'killtheclockhd check', 'kind comment', 'kluivert son', 'know dance', 'know music', 'know people', 'know probably', 'know thing', 'know true', 'know y39all', 'kodaline imagine', 'kpop parody', 'la remezcla', 'lad named', 'lake duzafizz', 'lame 2004', 'lamest world', 'lana del', 'land supreme', 'large amount', 'later still', 'latest model', 'laugh please', 'learn kid', 'learn something', 'least one', 'led hdtv', 'leeched porno', 'leeched sucking', 'left africa', 'left comment', 'left spam', 'leisure cease', 'let get', 'let make', 'lie shakira', 'life like', 'life real', 'life thank', 'life thumb', 'life won39t', 'like 10', 'like 1000000000', 'like adele', 'like charity', 'like comment', 'like euw', 'like love', 'like must', 'like please', 'like psn', 'like shakira', 'like song', 'like subscribing', 'like thumb', 'like today', 'like unique', 'like vine', 'like watchv5tu9gn1l310', 'like year', 'likebr year', 'lima você', 'line please', 'link donate', 'link facebook', 'link mileycelebnewscouk', 'link subscribe', 'link thergloveblogspotin201308blogpost_10html', 'link wholehearted', 'lip synch', 'listen doesn39t', 'listen gorgeous', 'listen new', 'listen one', 'listen soo', 'listenersupported want', 'listening gypsy', 'live aid', 'live card', 'live small', 'lively love', 'lol got', 'lol love', 'long ago', 'look channel', 'look foward', 'look gorgeous', 'look nice', 'lord trumpetcallofgodonline', 'lot cover', 'lot money', 'love check', 'love dis', 'love football', 'love itt', 'love itttttttt', 'love mind', 'love miusic', 'love much', 'love nothing', 'love one', 'love shakira', 'love shakirabr', 'love shakiralt33333', 'love shakiria', 'love shkira', 'love song', 'love watching', 'love woman', 'love ya', 'loved song', 'lovely lively', 'lover39s guess', 'loving brother', 'loyal following', 'lt3 shakira', 'lt3 song', 'lt3br keep', 'luxury donate', 'macabre crestboot', 'macbook air', 'macbook pro', 'macklemore pink', 'made 500', 'made cd', 'made person', 'made seem', 'made song', 'madly love', 'make 4000', 'make 4500', 'make another', 'make believerbr', 'make easy', 'make first', 'make forgot', 'make happen', 'make happy', 'make lot', 'make miss', 'make money', 'make music', 'make thousand', 'make video', 'making 3000', 'making income', 'making music', 'making type', 'man39s cock', 'many ambition', 'many dislike', 'many disliked', 'many subscriber', 'marketer click', 'martin needed', 'martyr pray', 'mary pray', 'master itquot', 'mate definitily', 'mate hopefully', 'matter help', 'matter join', 'matter much', 'maybe change', 'maybe dreamer', 'maybe even', 'mean africa', 'mean lot', 'mean world', 'meaning song', 'meaningful song', 'meat discus', 'medium job', 'meet johnny', 'meet richest', 'memory peaceful', 'memory vibe39s', 'men woman', 'mess around', 'message gta', 'mi canal', 'might best', 'miley cyrus', 'mileycelebnewscouk case', 'million view', 'million viewsbr', 'millionsbr br', 'min read', 'mind master', 'mini 250', 'minute could', 'minute daily', 'minute time', 'mio meh', 'miss br', 'miss opportunity', 'miss world', 'mississippi please', 'mixtape check', 'mixtapecheck new', 'model 32gb', 'moment give', 'moment ricky', 'money 50k', 'money advertise', 'money advertisement', 'money advertisiments', 'money african', 'money betfair', 'money check', 'money easily', 'money fast', 'money hopme', 'money huge', 'money it39s', 'money like', 'money numberless', 'money online', 'money something', 'moneygqcom check', 'moneygqcom make', 'moneygqcom visit', 'moneyquot shot', 'month firepacom', 'month moneygqcom', 'month search', 'month zonepacom', 'monthly incomeonly', 'monthly read', 'morning fighting', 'mother admirable', 'mother amiable', 'mother approve', 'mother chaste', 'mother christ', 'mother creator', 'mother divine', 'mother god', 'mother good', 'mother inviolate', 'mother pure', 'mother redeemer', 'mother undefiled', 'motherlandbr thankyou', 'mta channelbr', 'much better', 'much lt3br', 'much one', 'much people', 'much sinned', 'muchshakira really', 'murder innocent', 'music anyone', 'music completely', 'music da', 'music eight', 'music fan', 'music heard', 'music i39m', 'music industry', 'music lover39s', 'music please', 'music producer', 'music share', 'music sound', 'music thumb', 'music videosbr', 'music wish', 'music world', 'music would', 'music yall', 'musicbr br', 'musician music', 'musiclyrics amp', 'musicvideo 3939life39s', 'muslim really', 'must stop', 'na earn', 'na honest', 'na laugh', 'na play', 'name cause', 'name39s anderson', 'named jim', 'namepicture enjoy', 'namepicture thank', 'nation email', 'nation founded', 'need prior', 'needed smh', 'neeru105 gmailcom', 'neighbor stand', 'netherland france', 'never forget', 'never get', 'new album', 'new consumer', 'new cover', 'new friend', 'new halloween', 'new men', 'new mixtape', 'new mixtapecheck', 'new movement', 'new musicvideo', 'new song', 'new video', 'new way', 'new white', 'newest miley', 'news support', 'nice day', 'nice love', 'nice mate', 'nice meet', 'nice song', 'nice vídeo', 'nicely view', 'nick much', 'night plot', 'nikon d90', 'none god', 'northland paranormal', 'nothing come', 'nothing live', 'nothing loyal', 'nothing that39s', 'nsa spying', 'number transport', 'numberless number', 'nummber patrik', 'não conhece', 'obtain new', 'offical song', 'oh god', 'old boy', 'old check', 'old man39s', 'old realized', 'old still', 'omg facebook', 'omg listen', 'omg love', 'one africa', 'one best', 'one billion', 'one bookmaker', 'one chance', 'one day', 'one doesn39t', 'one fave', 'one faves', 'one please', 'one trayvon', 'one two', 'online effort', 'online get', 'online marketer', 'online start', 'online website', 'online without', 'online work', 'open google', 'openly street', 'opportunity give', 'original music', 'original musiclyrics', 'original sin', 'original song', 'others freedom', 'others see', 'others subscribe', 'ouf ouf', 'ouf ouffffffffffffffffff', 'ourself know', 'page it39s', 'page thanks', 'page tvcmcadavidweebly', 'page youtube', 'pagee please', 'paid mess', 'paid respond', 'paid survey', 'paid upto', 'paranormal evidence', 'paranormal society', 'parody please', 'part comforter', 'part holy', 'partyman318 fr', 'pas kind', 'passed saturday', 'passionate singer', 'passionbr br', 'past br', 'past present', 'patriarch pray', 'patrik kluivert', 'patriot act', 'paul dot', 'paul hrefhttpwwwyoutubecomwatchvprpeedmmmq0ampt1m00s100a', 'paul spent', 'pay get', 'pay obtain', 'pc apple', 'peace pray', 'peaceful seat', 'peaceful unit', 'people can39t', 'people dislike', 'people earth', 'people friend', 'people gave', 'people give', 'people make', 'people understand', 'people world', 'pepelexa zealous', 'per month', 'perfect lt3', 'perform every', 'perhaps seen', 'perry saying', 'person continue', 'person ice', 'perverse abominable', 'petitionbr hrefhttpwwwthepetitionsitecom387433550stopanimaltraffickingcidheaderclickhttpwwwthepetitionsitecom387433550stopanimaltraffickingcidheaderclicka', 'piano cover', 'pink countless', 'piss bit', 'plausible summer', 'play game', 'play guitar', 'playerhis team', 'playerto amazement', 'playlist youtube', 'playlist youtubebr', 'playlist youtubecentral', 'plea subscribe', 'plea subscribeeeeeeeeee', 'pleasant hear', 'please check', 'please come', 'please could', 'please give', 'please go', 'please google', 'please hear', 'please i39ll', 'please like', 'please listen', 'please share', 'please subscribe', 'please take', 'please visit', 'plot evil', 'plus ive', 'plus she39s', 'plz wilsubscribe', 'poor one', 'population video', 'porno video', 'portugal belgium', 'possiblequot winner', 'posted celebrity', 'postponing vote', 'ppl check', 'prank crank', 'pray help', 'pray holy', 'pray mother', 'pray queen', 'prepare historical', 'present especially', 'press quotthumbs', 'pretty lt3', 'price320 camera', 'price360 sony', 'price385 samsung', 'price390 apple', 'price390 ultrabooks', 'price510 allinone', 'price515 purchase', 'prior skill', 'privacy home', 'pro 13', 'pro apple', 'probably pas', 'producer song', 'profile tape', 'promise i39ll', 'promotes terrorism', 'prophet pray', 'protect hrefhttpithtithta', 'protect joining', 'protest filibuster', 'proud moment', 'prove ourself', 'prove please', 'ps4 200', 'psn cardsxbox', 'purchase online', 'pure pray', 'push closer', 'put money', 'quality music', 'queen angel', 'queen apostle', 'queen conceived', 'queen confessor', 'queen family', 'queen holy', 'queen martyr', 'queen patriarch', 'queen peace', 'queen prophet', 'queen saint', 'queen virgin', 'quid far', 'quid thus', 'quot best', 'quot ww', 'quotdribbleproshotquot yet', 'quothelp humanity', 'quoti39m africanquot', 'quotnoquot discrimination', 'quotthis time', 'quotthumbs upquot', 'quotversace freestyle', 'quotwake fiddle', 'quotwe love', 'quotyeahquot dream', 'quotyour disguisequot', 'racist could', 'raise money', 'rand fight', 'rand paul', 'rand protect', 'rand senator', 'rand tell', 'range social', 'rapper singer', 'rapper we39re', 'rappersinger estonia', 'reach billion', 'reach million', 'reach one', 'read 19', 'read check', 'read could', 'read go', 'read thank', 'reading sing', 'reading thanks', 'real affiliated', 'real online', 'real paranormal', 'real thank', 'realized song', 'really appreciate', 'really ask', 'really can39t', 'really egoistic', 'really good', 'really love', 'really madly', 'reason 1it', 'reason also', 'recipe hilarious', 'recognizes money', 'recommend apple', 'record new', 'recording fifa', 'redeemer pray', 'reed case', 'refused euro', 'regret feel', 'regret give', 'regret thank', 'remember forget', 'remember song', 'remember torunament', 'remezcla check', 'remix click', 'remix miley', 'remix type', 'renewal rand', 'repay hear', 'replay button', 'replay love', 'respond fast', 'reveling hate', 'rey drake', 'richest online', 'ricky martin', 'right commit', 'right freedom', 'right privacy', 'right way', 'righteousness matter', 'risk acquiring', 'risk claiming', 'roar 50', 'rocksbr span', 'roll space', 'rosary pray', 'roughly 100', 'rugby work', 's4 iv', 's4 mini', 'said stop', 'saint pray', 'salvation gained', 'sam love', 'samsung galaxy', 'saturday morning', 'saved salvation', 'savior go', 'savior sin', 'say possiblequot', 'say quotnoquot', 'say think', 'saying katy', 'search ej', 'search google', 'search quotwake', 'seat country', 'second life', 'secret google', 'secret video', 'secure bonus', 'see channel', 'see check', 'see itbr', 'see made', 'see shakira', 'see song', 'see thank', 'see thisbr', 'seem like', 'seen newest', 'seen perform', 'selecting wager', 'senate floor', 'senator congress', 'senator rand', 'send others', 'sexy drive', 'sexy shakira', 'shakifans close', 'shakira beautiful', 'shakira become', 'shakira best', 'shakira different', 'shakira favourite', 'shakira football', 'shakira good', 'shakira guruofmovie', 'shakira hasbr', 'shakira keep', 'shakira love', 'shakira perfect', 'shakira rocksbr', 'shakira song', 'shakira sorry', 'shakira voice', 'shakira waka', 'shakira wiredo', 'shakira39s waka', 'shall repay', 'shame terrorist', 'share i39ve', 'share link', 'share replay', 'share song', 'share suscribe', 'she39s awesome', 'she39s cute', 'she39s pretty', 'she39s sucking', 'shit sooooo', 'shit yall', 'shot jawan', 'sign app', 'sign link', 'significantly boost', 'sillyquot worth', 'simple thumb', 'simply download', 'sin go', 'sin pray', 'sin truly', 'sing camp', 'sing speaks', 'sing write', 'singer expecting', 'singer look', 'singer music', 'singer wooooo', 'singing there', 'singlewave spourmo', 'sinned past', 'sister please', 'site believe', 'site bitly1bsefqe', 'site facebooktwitter', 'site hhnl', 'site watch', 'skill experience', 'skill time', 'skin tell', 'skip comment', 'slr camera', 'small town', 'smart free', 'smoking comment', 'soccer football', 'soccer know', 'soccer playerhis', 'soccer promotes', 'soccer skill', 'soccer team', 'social medium', 'social working', 'society youtube', 'someone care', 'someone leeched', 'something long', 'something made', 'something one', 'son fantastic', 'son share', 'song 2010', 'song absolutely', 'song africa', 'song always', 'song ampi', 'song awesome', 'song beautiful', 'song beauty', 'song br', 'song bring', 'song called', 'song check', 'song choice', 'song completely', 'song eva', 'song ever', 'song everbr', 'song expect', 'song female', 'song french', 'song go', 'song including', 'song life', 'song like', 'song love', 'song much', 'song muchshakira', 'song never', 'song open', 'song please', 'song racist', 'song sad', 'song shakira', 'song sing', 'song soccer', 'song song', 'song special', 'song subscribed', 'song suck', 'song sure', 'song teenage', 'song think', 'song thumsb', 'song time', 'song two', 'song video', 'song waka', 'song world', 'song write', 'song writer', 'song year', 'songwriter columbus', 'songwriter there', 'sony 60inch', 'sony vaio', 'soo good', 'sooooo autotuned', 'sooooo beautiful', 'sorry anyone', 'sorry anything', 'sorry bad', 'sorry im', 'sorry video', 'sound amazing', 'sound like', 'sound spanish', 'sound weird', 'south africa', 'space prepare', 'space view', 'spain british', 'spam sorry', 'spam truly', 'spamming everyone', 'span classproflinkwrapperspan', 'spanish make', 'spanish people', 'spare min', 'spare minute', 'speaks language', 'special song', 'speech thanks', 'spending 20', 'spending africa', 'spent 105', 'spirit i39m', 'spourmo burder', 'spread truth', 'spread word', 'spying american', 'stand bring', 'stand right', 'start 025', 'start working', 'started earning', 'started making', 'statement conciliate', 'step forward', 'steven reed', 'stil best', 'stil lisening', 'still amazing', 'still love', 'still reading', 'still watching', 'stop nsa', 'stop racist', 'stop smoking', 'stop wasting', 'store called', 'strategizes edge', 'street perverse', 'stretch earth', 'student who39s', 'sub back', 'submits behavior', 'subscribe amp', 'subscribe back', 'subscribe brake', 'subscribe channel', 'subscribe daily', 'subscribe feed', 'subscribe gamezz', 'subscribe like', 'subscribe look', 'subscribe love', 'subscribe page', 'subscribe pagee', 'subscribe please', 'subscribe requite', 'subscribe subscribe', 'subscribe thank', 'subscribe want', 'subscribe wil', 'subscribe win', 'subscribe would', 'subscribe youtube', 'subscribed itbr', 'subscribeeeeeeeeee channnnnnelll', 'subscriber compared', 'subscriber make', 'subscriber word', 'subscribing liking', 'subscribing that39d', 'subscription would', 'substantially better', 'successcheers loving', 'successful memory', 'successful musician', 'sucking fucking', 'sucking old', 'summer submits', 'super curly', 'super music', 'support discrimination', 'support fight', 'support rand', 'support say', 'supreme courtthanks', 'survey download', 'survey home', 'suscribe comment', 'suscribite mi', 'suscríbase click', 'swagfriends com', 'swear shakira', 'swim enlist', 'synch terrible', 'take half', 'take look', 'take minute', 'take moment', 'take time', 'talking killing', 'tan ybuwyn', 'tape banging', 'team made', 'team mate', 'technique put', 'technique wager', 'teenage year', 'tell news', 'tell something', 'tell support', 'terrorism bad', 'terrorist muslim', 'thank adam', 'thank amp', 'thank br', 'thank much', 'thank nice', 'thank people', 'thank please', 'thank wafence', 'thanks dont', 'thankyou shakira', 'that39d awesome', 'that39s left', 'that39s reason', 'there singing', 'there song', 'there thousand', 'thing annoying', 'thingsbr br', 'think iniesta39s', 'think samebr', 'think song', 'think working', 'thisbr br', 'thisbr hrefhttpadflyhttpadflya', 'thousand cool', 'thousand maybe', 'three shakira', 'thumb comment', 'thumb found', 'thumb think', 'thumb watching', 'thumb would', 'thus far', 'time africa', 'time africabr', 'time africaquot', 'time amp', 'time check', 'time get', 'time hear', 'time read', 'time spending', 'time transformed', 'time turned', 'tinyurldotcomslashmxh2y77 fear', 'today making', 'today someone', 'today video', 'together impossible', 'took time', 'top three', 'torunament like', 'totally love', 'town come', 'trafficking petitionbr', 'transformed fausto', 'transport trade', 'trayvon motherlandbr', 'tried quotdribbleproshotquot', 'true word', 'truly believe', 'truly sorry', 'trumpetcallofgodonline co', 'truth spread', 'trying enter', 'trying make', 'tube video', 'turned nick', 'tvcmcadavidweebly com', 'twitter get', 'two cover', 'two reason', 'type cge', 'type code', 'type music', 'type shakira', 'ultrabooks sony', 'un patriot', 'un vistazo', 'uncle said', 'undefiled pray', 'underrated betterbr', 'understand thisbr', 'unique that39s', 'unit arbitrate', 'united stand', 'unlocked wifi4g', 'upquot others', 'upto 25', 'useful free', 'usl past', 'vaio pro', 'vanstone finding', 'vanstone secret', 'vanstone selecting', 'versace remix', 'vibe39s miss', 'video animation', 'video animator', 'video called', 'video celeb', 'video demonstrating', 'video donating', 'video featuring', 'video least', 'video leeched', 'video posted', 'video prank', 'video she39s', 'video subscribe', 'video subscription', 'video youtube', 'video youtubebr', 'videosbr br', 'vids subscribe', 'view 868', 'view convinced', 'view i39ve', 'view roar', 'view vids', 'viewsbr dark', 'viewsbr hrefhttpswwwyoutubecomwatchvprpeedmmmq0httpswwwyoutubecomwatchvprpeedmmmq0a', 'vincent remix', 'vine subscribe', 'virgin pray', 'virgin virgin', 'visit channel', 'visit firepacom', 'visit link', 'visit moneygqcom', 'visit quot', 'visit site', 'visit web', 'visit website', 'visit zonepacom', 'vistazo la', 'você não', 'voice different', 'voice might', 'voice sound', 'voice wow', 'vote week', 'voucher like', 'vídeo shakira', 'wager free', 'wager something', 'waka best', 'waka br', 'waka eh', 'waka first', 'waka it39s', 'waka rule', 'waka waka', 'waka wakad', 'wakad check', 'wake search', 'wallet sign', 'wan na', 'wanderfol love', 'want goal', 'want hear', 'want make', 'want new', 'want see', 'want successful', 'want view', 'want win', 'wasn39t live', 'wasting time', 'watch share', 'watch smart', 'watch video', 'watched large', 'watching 2015', 'watching football', 'watchvdtqcftr1fac justien', 'wats good', 'way enormously', 'way i39ll', 'way make', 'way significantly', 'way super', 'way want', 'way39s subscribe', 'we39re african', 'we39re gon', 'web site', 'web wellcomemdblogfacom', 'website beneath', 'website called', 'website find', 'website link', 'website make', 'website mileycelebnewscouk', 'website oldchattk', 'website taaeecom', 'website vanstone', 'week constitution', 'weird plus', 'weird technique', 'well done', 'wery good', 'whats found', 'white price360', 'white price390', 'who39s also', 'whole truth', 'wholehearted support', 'whose watching', 'wickedness celebrated', 'wide range', 'wifi4g 97in', 'wil subscribe', 'willing help', 'wilsubscribe frndzzl', 'win capbr', 'win money', 'winner successcheers', 'winooze absorbing', 'wish awesome', 'wish see', 'without investmentjust', 'without original', 'wk song', 'woman succeeds', 'woman tell', 'womanly tan', 'won39t regret', 'wont regret', 'word football', 'word gain', 'word lord', 'word someone', 'work 100100', 'work comfort', 'work harder', 'work help', 'work immediately', 'work like', 'working 40', 'working home', 'working it39s', 'working make', 'working student', 'world cup', 'world dont', 'world lot', 'world many', 'world population', 'world thank', 'world wide', 'worried loss', 'worth listen', 'would apprecitate', 'would click', 'would great', 'would highly', 'would like', 'would love', 'would nice', 'would step', 'wow muslim', 'wow5 yearsbr', 'wrecking ball', 'write lol', 'write original', 'writer making', 'ww estiloproduction', 'y39all check', 'ya shakira', 'yall got', 'yall killed', 'ybuwyn forgetful', 'yea stil', 'year ago', 'year exact', 'year later', 'year old', 'year soon', 'yet actually', 'yet search', 'you39re willing', 'youtube advertisement', 'youtube anyone', 'youtube channel', 'youtube check', 'youtube comment', 'youtube don39t', 'youtube killtheclockhd', 'youtube whatuknow', 'youtubebr quotthis', 'youtubers music', 'youtubers really', 'zonepacom check', 'zonepacom make', 'zonepacom visit']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer2.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a01b55a-94e9-44a1-b5a4-a01d803ff3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
